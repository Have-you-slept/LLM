import time
import os
import gradio as gr
# 1. è°ƒæ•´æ–‡æ¡£åŠ è½½å™¨æ¨¡å—è·¯å¾„ï¼ˆè¿ç§»è‡³ langchain_communityï¼‰
from langchain_community.document_loaders import DirectoryLoader
# 2. è°ƒæ•´ ChatGLM LLM æ¨¡å—è·¯å¾„ï¼ˆè¿ç§»è‡³ langchain_communityï¼‰
from langchain_community.llms import ChatGLM
from langchain_core.prompts import PromptTemplate
from langchain_text_splitters import CharacterTextSplitter
# 3. è°ƒæ•´ HuggingFaceEmbeddings æ¨¡å—è·¯å¾„ï¼ˆè¿ç§»è‡³ langchain_communityï¼‰
from langchain_community.embeddings import HuggingFaceEmbeddings
# 4. è°ƒæ•´ Chroma å‘é‡å­˜å‚¨æ¨¡å—è·¯å¾„ï¼ˆè¿ç§»è‡³ langchain_communityï¼‰
from langchain_community.vectorstores import Chroma
# æ–°å¢ï¼šä½¿ç”¨ LangChain æ ¸å¿ƒç»„ä»¶æ›¿ä»£ RetrievalQAï¼ˆæ— éœ€ langchain.chainsï¼‰
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from neo4j import search  # çŸ¥è¯†å›¾è°±ç›¸å…³ï¼ˆä¿æŒä¸å˜ï¼‰

# è®¾ç½®åˆå§‹åŒ–æ˜¯å¦ä½¿ç”¨çŸ¥è¯†å›¾è°±æ•°æ®åº“æœç´¢ç›¸å…³çŸ¥è¯†ç‚¹
neo4j = False
if neo4j:
    neo4j_use = "çŸ¥è¯†å›¾è°±å·²å¯åŠ¨"
else:
    neo4j_use = "çŸ¥è¯†å›¾è°±å·²å…³é—­"


def load_documents(directory="document"):
    loader = DirectoryLoader(directory)
    documents = loader.load()
    text_spliter = CharacterTextSplitter(chunk_size=256, chunk_overlap=0)
    split_docs = text_spliter.split_documents(documents)
    return split_docs


def load_embedding_model(local_model_path):
    encode_kwargs = {"normalize_embeddings": False}
    # ä½¿ç”¨cpu
    # model_kwargs = {"device": "cpu"}
    # cuda==11.8 pytorch==2.1.0 å¯ç”¨
    model_kwargs = {"device": "cpu"}
    return HuggingFaceEmbeddings(
        model_name=local_model_path,
        model_kwargs=model_kwargs,
        encode_kwargs=encode_kwargs
    )


def store_chroma(docs, embeddings, persist_directory="VectorStore"):
    # 5. Chroma åˆå§‹åŒ–å‚æ•°å…¼å®¹ï¼ˆæ— éœ€ä¿®æ”¹ï¼Œlangchain_community ä¿æŒä¸€è‡´æ¥å£ï¼‰
    db = Chroma.from_documents(docs, embeddings, persist_directory=persist_directory)
    db.persist()
    return db


def add_text(history, text):
    history += [(text, None)]
    print(history)
    return history, gr.update(value="", interactive=False)


def add_file(history, file):
    global qa_chain, retriever  # ä¿®æ”¹ï¼šä½¿ç”¨å…¨å±€ qa_chain å’Œ retriever
    directory = os.path.dirname(file.name)
    documents = load_documents(directory)
    db = store_chroma(documents, embeddings)
    retriever = db.as_retriever()  # æ›´æ–°æ£€ç´¢å™¨
    # é‡æ–°æ„å»º QA é“¾ï¼ˆæ›¿æ¢åŸ qa.retriever = retrieverï¼‰
    qa_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | QA_PROMPT
        | llm
        | StrOutputParser()
    )
    history = history + [((file.name,), None)]
    return history


def bot(history):
    global neo4j, neo4j_use, qa_chain  # ä¿®æ”¹ï¼šä½¿ç”¨å…¨å±€ qa_chain
    if not history:
        return history
    message = history[-1][0]
    search_ans = False
    if neo4j:
        search_ans = search.search_relate(message)
    extra = ""
    if search_ans:
        extra = "\n\n-------------------------------------------\n\nä»¥ä¸‹æ˜¯æ ¹æ®ä½ çš„æé—®æ¨èçš„çŸ¥è¯†ç‚¹:\n" + search_ans
    if isinstance(message, tuple):
        response = "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ï¼"
    elif (message == "æ‰“å¼€çŸ¥è¯†å›¾è°±") or (message == "å…³é—­çŸ¥è¯†å›¾è°±"):
        response = neo4j_use
    else:
        # ä¿®æ”¹ï¼šä½¿ç”¨ qa_chain æ›¿ä»£åŸ qa({"query": message})['result']
        response = qa_chain.invoke(message)
        response += extra
    history[-1][1] = ""
    for character in response:
        history[-1][1] += character
        time.sleep(0.01)
        yield history


def btn_neo4j_click(history):
    global neo4j_use, neo4j
    if neo4j_use == "çŸ¥è¯†å›¾è°±å·²å…³é—­":
        neo4j = True
        neo4j = search.connect_neo4j(neo4j)
    else:
        neo4j = False
        neo4j = search.connect_neo4j(neo4j)
    if neo4j:
        neo4j_use = "çŸ¥è¯†å›¾è°±å·²å¯åŠ¨"
        neo4j__use = "æ‰“å¼€çŸ¥è¯†å›¾è°±"
    else:
        neo4j_use = "çŸ¥è¯†å›¾è°±å·²å…³é—­"
        neo4j__use = "å…³é—­çŸ¥è¯†å›¾è°±"
    btn_neo4j.value = neo4j_use
    print("çŸ¥è¯†å›¾è°±çŠ¶æ€:", neo4j_use)
    history += [(neo4j__use, None)]
    return history


# -------------------------- æ–°å¢ï¼šæ ¸å¿ƒæ›¿æ¢é€»è¾‘ --------------------------
def format_docs(docs):
    """å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£æ‹¼æ¥ä¸ºä¸Šä¸‹æ–‡æ–‡æœ¬"""
    return "\n\n".join([doc.page_content for doc in docs])

# å…¨å±€å˜é‡ï¼šå®šä¹‰ QA æç¤ºæ¨¡æ¿ï¼ˆåŸ QA å˜é‡é‡å‘½åä¸º QA_PROMPTï¼‰
QA_PROMPT = PromptTemplate.from_template(
    """æ ¹æ®ä¸‹é¢çš„ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰å†…å®¹å›ç­”é—®é¢˜ã€‚
å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±å›ç­”ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚
ç­”æ¡ˆæœ€å¤š400ä¸ªå­—

ä½†æ˜¯å¦‚æœé—®åˆ°ä¸‹é¢çš„å†…å®¹ï¼Œå°±å›å¤å¯¹åº”çš„é“¾æ¥ + å¯¹è¯¥ç§‘ç›®çš„ä»‹ç» + å¤ä¹ æ–¹æ³•ï¼Œæ¯éƒ¨åˆ†æ¢è¡Œå¤„ç†ï¼Œä¸€ç™¾å­—å·¦å³
ç§‘ç›®å’Œé“¾æ¥çš„å¯¹åº”å…³ç³»å¦‚ä¸‹ï¼š
å¤§å­¦ç‰©ç†ï¼šé“¾æ¥: https://pan.baidu.com/s/19B5uc8Mjr0SPuQZ0I9U8PA æå–ç : dm7a
æ“ä½œç³»ç»Ÿï¼šé“¾æ¥: https://pan.baidu.com/s/1ZYjE6Jk9Uf2c85Ya84KZXA æå–ç : pb3i
çº¿æ€§ä»£æ•°ï¼šé“¾æ¥: https://pan.baidu.com/s/1dfK6Z1He03LkhFy5nLz1zA æå–ç : thd9
è®¡ç®—æœºç»„æˆåŸç†ï¼šé“¾æ¥: https://pan.baidu.com/s/1a2f8uI42J3vOF-EWLmv9ow æå–ç : k8hw
è®¡ç®—æœºç½‘ç»œï¼šé“¾æ¥: https://pan.baidu.com/s/1ccrUng8ViMoIcZVhxEgJXA æå–ç : f14e

{context}

é—®é¢˜ï¼š{question}

"""
)
# ----------------------------------------------------------------------


if __name__ == "__main__":
    # åŠ è½½æœ¬åœ°åµŒå…¥æ¨¡å‹
    embeddings = load_embedding_model(local_model_path=r'D:\simple_RAG_with_LLMs_API\text2vec-base-chinese')
    # åŠ è½½å‘é‡æ•°æ®åº“
    if not os.path.exists('VectorStore'):
        documents = load_documents()
        db = store_chroma(documents, embeddings)
    else:
        # 7. Chroma åŠ è½½å‚æ•°å…¼å®¹ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
        db = Chroma(persist_directory='VectorStore', embedding_function=embeddings)
    # ä½¿ç”¨æœ¬åœ°apiæä¾›çš„å¤§æ¨¡å‹æœåŠ¡
    llm = ChatGLM(
        endpoint_url='http://127.0.0.1:8000',
        max_token=2048,
        top_p=0.9
    )
    # -------------------------- ä¿®æ”¹ï¼šæ„å»º QA é“¾ï¼ˆæ›¿ä»£ RetrievalQAï¼‰ --------------------------
    retriever = db.as_retriever()  # åˆ›å»ºæ£€ç´¢å™¨
    # æ„å»ºæ£€ç´¢-ç”Ÿæˆé“¾ï¼šæ£€ç´¢æ–‡æ¡£ â†’ æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ â†’ æ‹¼æ¥æç¤º â†’ LLMç”Ÿæˆ â†’ è¾“å‡ºè§£æ
    qa_chain = (
        {"context": retriever | format_docs,  # æ£€ç´¢å¹¶æ ¼å¼åŒ–æ–‡æ¡£
         "question": RunnablePassthrough()}  # ä¼ é€’ç”¨æˆ·é—®é¢˜
        | QA_PROMPT  # æ‹¼æ¥æç¤ºæ¨¡æ¿
        | llm  # è°ƒç”¨å¤§æ¨¡å‹
        | StrOutputParser()  # è§£æè¾“å‡ºä¸ºå­—ç¬¦ä¸²
    )
    # ---------------------------------------------------------------------------------------
    # è®¾ç½®å‰ç«¯äº¤äº’é¡µé¢ï¼ˆä¿æŒä¸å˜ï¼‰
    with gr.Blocks(
            theme=gr.themes.Soft(
                primary_hue=gr.themes.Color(
                    name="custom_blue",
                    c50="#e3f2fd", c100="#bbdefb", c200="#90caf9",
                    c300="#64b5f6", c400="#42a5f5", c500="#2196f3",
                    c600="#1e88e5", c700="#1976d2", c800="#1565c0", c900="#0d47a1"
                ),
                secondary_hue=gr.themes.Color(name="custom_gray", c500="#616161"),
                neutral_hue=gr.themes.Color(name="custom_light", c500="#f5f5f5")
            ),
            css="""
        /* å…¨å±€å¸ƒå±€ä¼˜åŒ– */
        .gradio-container { max-width: 1200px !important; margin: 0 auto; padding: 2rem; }
        body { background: linear-gradient(135deg, #f5f7fa 0%, #e4e9f2 100%); }

        /* Chatbotæ ·å¼å¢å¼º */
        #AIåŠ©æ‰‹ { height: 600px !important; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
        .gr-chatbot .user-bubble { background-color: #e3f2fd !important; color: #0d47a1 !important; border-radius: 18px !important; padding: 12px 18px !important; font-size: 16px !important; }
        .gr-chatbot .bot-bubble { background-color: #f5f5f5 !important; color: #616161 !important; border-radius: 18px !important; padding: 12px 18px !important; font-size: 16px !important; }
        .gr-chatbot .avatar { width: 40px !important; height:40px !important; border-radius:50% !important; }

        /* è¾“å…¥åŒºåŸŸæ ·å¼ä¼˜åŒ– */
        .gr-textbox { border-radius: 24px !important; padding: 12px 20px !important; font-size:16px !important; border:1px solid #e0e0e0 !important; box-shadow:0 2px 6px rgba(0,0,0,0.05) !important; }
        .gr-textbox:focus { border-color: #2196f3 !important; outline:none !important; box-shadow:0 0 0 3px rgba(33,150,243,0.2) !important; }

        /* æŒ‰é’®æ ·å¼å‡çº§ */
        .gr-button { border-radius:24px !important; padding:8px 16px !important; font-size:16px !important; margin:0 4px !important; transition:all 0.3s ease !important; }
        .gr-button:hover { transform: translateY(-2px) !important; box-shadow:0 4px 8px rgba(0,0,0,0.1) !important; }
        .gr-upload-button { background-color:#42a5f5 !important; color:white !important; }
        .gr-upload-button:hover { background-color:#1e88e5 !important; }
        .gr-button[value*="å¼€å…³çŸ¥è¯†å›¾è°±"] { background-color:#616161 !important; color:white !important; }
        .gr-button[value*="å·²å¼€å¯"] { background-color:#2196f3 !important; }
        """
    ) as demo:
        # çŠ¶æ€å˜é‡ï¼šè®°å½•çŸ¥è¯†å›¾è°±æ˜¯å¦å¼€å¯
        neo4j_enabled = gr.State(False)

        # æ ‡é¢˜ä¸æè¿°
        gr.Markdown("# ğŸ¤– AIåŠ©æ‰‹ï¼ˆçŸ¥è¯†å›¾è°±å¢å¼ºç‰ˆï¼‰", elem_id="title")
        gr.Markdown("### è¾“å…¥é—®é¢˜æˆ–ä¸Šä¼ æ–‡ä»¶ï¼Œä½“éªŒæ™ºèƒ½äº¤äº’", elem_id="subtitle")

        # Chatbotç»„ä»¶
        chatbot = gr.Chatbot(
            [],
            elem_id="AIåŠ©æ‰‹",
            bubble_full_width=False,
            avatar_images=(None, os.path.join(os.path.dirname(__file__), "bot.jpg")),
            bubbleBorderRadius=18,
            bubblePadding=12
        )

        # è¾“å…¥åŒºåŸŸå¸ƒå±€
        with gr.Row(elem_id="input-row", variant="compact"):
            query = gr.Textbox(
                scale=5,
                show_label=False,
                placeholder="è¾“å…¥é—®é¢˜å¹¶æŒ‰ä¸‹å›è½¦é”®æäº¤",
                container=False,
                interactive=True
            )
            btn_upload = gr.UploadButton("ğŸ“ ä¸Šä¼ å¤–æŒ‚æ•°æ®åº“", file_types=['txt'], elem_id="upload-btn")
            btn_neo4j = gr.Button(value="å¼€å…³çŸ¥è¯†å›¾è°±ï¼ˆæœªå¼€å¯ï¼‰", elem_id="neo4j-btn")

        # äº¤äº’é€»è¾‘ç»‘å®š
        # 1. çŸ¥è¯†å›¾è°±å¼€å…³
        btn_neo4j.click(
            fn=btn_neo4j_click,
            inputs=[chatbot, neo4j_enabled],
            outputs=[chatbot, neo4j_enabled, btn_neo4j],
            show_progress=True
        )

        # 2. æ–‡æœ¬è¾“å…¥æäº¤
        query.submit(
            fn=add_text,
            inputs=[chatbot, query],
            outputs=[chatbot, query]
        ).then(
            fn=bot,
            inputs=chatbot,
            outputs=[chatbot, query]
        )

        # 3. æ–‡ä»¶ä¸Šä¼ å¤„ç†
        btn_upload.upload(
            fn=add_file,
            inputs=[chatbot, btn_upload],
            outputs=chatbot,
            show_progress=True
        )
